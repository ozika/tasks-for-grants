{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/drive/postdoc/grants/resources/tasks-for-grants'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, os, sys \n",
    "from groo.groo import get_root\n",
    "\n",
    "os.path.join(get_root(\".tasks_root\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_bin_arr(size, no_relevant):\n",
    "\n",
    "    if no_relevant > size:\n",
    "        raise ValueError(\"Number of relevant values (1s) cannot exceed the size of the array.\")\n",
    "    \n",
    "    # Step 1: Generate the binary array\n",
    "    binary_array = np.zeros(size, dtype=int)\n",
    "    binary_array[:no_relevant] = 1\n",
    "    np.random.shuffle(binary_array)\n",
    "    \n",
    "    # Step 2: Assign sequential numbers to positions where the binary array has 1s\n",
    "    sequential_numbers = np.arange(1, no_relevant + 1)  # Generate sequential numbers starting from 1\n",
    "    np.random.shuffle(sequential_numbers)  # Shuffle the sequential numbers\n",
    "    result_array = np.zeros_like(binary_array)  # Create an array of the same shape as the binary array\n",
    "    result_array[binary_array == 1] = sequential_numbers  # Assign shuffled numbers to 1 positions\n",
    "    \n",
    "    return binary_array, result_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "no_relevant = 3\n",
    "no_contexts = 6\n",
    "no_shown_t = 3\n",
    "\n",
    "reps = 1\n",
    "n_targets = 2\n",
    "\n",
    "noise = 2 # standard deviation \n",
    "\n",
    "n_stim_total = 10\n",
    "\n",
    "conds = [\"low\", \"low-mid\", \"mid\", \"mid-high\", \"high\"]\n",
    "lvls = dict({\n",
    "    \"irr\": [0, 0],\n",
    "    \"low\": [5, -15],\n",
    "    \"low-mid\": [15, -5],\n",
    "    \"mid\": [20, -20], \n",
    "    \"mid-high\": [20, -40],\n",
    "    \"high\": [-40, 20]\n",
    "})\n",
    "\n",
    "# trial no, target, c1_id, c1_v, c2_id, c2_v, c3_id, c3_v\n",
    "\n",
    "\n",
    "basic_sched = pd.DataFrame()\n",
    "ii = 1\n",
    "for no_relevant in [3]:\n",
    "    random_keys = random.sample(list(conds), no_relevant)\n",
    "    ordered_keys = sorted(random_keys, key=lambda k: lvls[k][1], reverse=True)  # Sort by the upper bound descending\n",
    "\n",
    "    while len(ordered_keys) < no_contexts:\n",
    "        ordered_keys.append(\"irr\")\n",
    "    relevance = [\"rel\" if key != \"irr\" else \"irr\" for key in ordered_keys]\n",
    "\n",
    "    stimuli = list(range(1, n_stim_total + 1))  # Stimuli numbered from 1 to 10\n",
    "    stim_chosen = no_relevant*10 + np.array(random.sample(stimuli, no_contexts))\n",
    "\n",
    "    positions = list(range(1, 7))  # Stimuli numbered from 1 to 10\n",
    "    stim_positions = random.sample(positions, no_contexts)\n",
    "\n",
    "\n",
    "    ## each rep will contain 2 trials (each for one target)\n",
    "    for r in range(reps):\n",
    "        print(r)\n",
    "        for t in range(n_targets):\n",
    "            #for s in range()\n",
    "            shown, order = gen_bin_arr(no_contexts,no_shown_t) \n",
    "            tdf = pd.DataFrame({\"tr_id\": ii,\n",
    "                                \"no_rel_ctxts\": no_relevant,\n",
    "                                \"target\": t+1, \n",
    "                                \"rel_cond\": \"rel\"+str(no_relevant),\n",
    "                                \"relevance\": relevance, \n",
    "                                \"condition\": ordered_keys,  \n",
    "                                \"condition_id\": np.arange(1,no_contexts+1),\n",
    "                                \"outcome\": [lvls[x][t] for x in ordered_keys],\n",
    "                                \"stim\": stim_chosen,  \n",
    "                                \"stim_positions\": stim_positions,\n",
    "                                \"shown\": shown, \n",
    "                                \"order\": order\n",
    "                                })\n",
    "            \n",
    "            basic_sched = pd.concat([basic_sched, tdf])\n",
    "            ii = ii + 1\n",
    "        \n",
    "\n",
    "\n",
    "df2 = basic_sched.copy()\n",
    "#basic_sched.to_csv(os.path.join(get_root(\".tasks_root\"), \"contextual-inference\", \"schedules\", \"sch1_filtered.csv\"))\n",
    "\n",
    "\n",
    "# filter and re-order schedule\n",
    "basic_sched = basic_sched.loc[basic_sched[\"shown\"]==1,]\n",
    "\n",
    "basic_sched = basic_sched.set_index([\"tr_id\", \"order\"]).unstack(\"order\")\n",
    "\n",
    "# Flatten column multi-index\n",
    "\n",
    "basic_sched.columns = [\n",
    "    f\"{col[0]}_stim{col[1]}\" if col[1] else col[0] for col in basic_sched.columns\n",
    "]\n",
    "constant_columns = [ \"no_rel_ctxts\", \"target\", \"rel_cond\", \"target\"]\n",
    "\n",
    "df_constants = df2[[\"tr_id\"] + constant_columns].drop_duplicates().set_index(\"tr_id\")\n",
    "\n",
    "# list of columns which need to be separated \n",
    "per_sim = [\"relevance\", \"condition\", \"condition_id\", \"outcome\", \"stim\", \"stim_positions\"]\n",
    "basic_sched = df_constants.merge(basic_sched.loc[:,[v + \"_stim\"+ str(st) for v in per_sim for st in [1,2,3]] ], left_index=True, right_on=\"tr_id\")\n",
    "\n",
    "# calculate total outcome\n",
    "basic_sched[\"outcome\"] = basic_sched.filter(regex=\"outcome\").sum(axis=1)\n",
    "\n",
    "basic_sched.to_csv(os.path.join(get_root(\".tasks_root\"), \"contextual-inference\", \"schedules\", \"sch1.csv\"))\n",
    "df2.to_csv(os.path.join(get_root(\".tasks_root\"), \"contextual-inference\", \"schedules\", \"sch1_full.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
